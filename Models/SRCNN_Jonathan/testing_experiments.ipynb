{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import PIL.Image as pil_image\n",
    "\n",
    "from models import SRCNN\n",
    "from utils import convert_rgb_to_ycbcr, convert_ycbcr_to_rgb, calc_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "\n",
    "image_name = '0001.png'\n",
    "path_to_outputs = f'outputs/{image_name[:-4]}'\n",
    "\n",
    "path_to_weights= 'pretrained/srcnn_x4.pth'\n",
    "# path_to_weights= 'pretrained/srcnn_x3.pth'\n",
    "\n",
    "# path_to_image = 'test_images/comic.png'\n",
    "# path_to_image = './data/butterfly_GT.bmp'\n",
    "path_to_image = f'./videos/test_set/AMVTG_004/truth/{image_name}'\n",
    "\n",
    "target_scale = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SRCNN(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
       "  (conv2): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv3): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "for n, p in torch.load(path_to_weights, map_location=lambda storage, loc: storage).items():\n",
    "    if n in state_dict.keys():\n",
    "        state_dict[n].copy_(p)\n",
    "    else:\n",
    "        raise KeyError(n)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "PSNR: 29.90\n"
     ]
    }
   ],
   "source": [
    "image = pil_image.open(path_to_image).convert('RGB')\n",
    "print(type(image))\n",
    "\n",
    "# Why are we resizing the image in this way?\n",
    "image.save(path_to_outputs + '_original.png')\n",
    "image_width = (image.width // target_scale) * target_scale\n",
    "image_height = (image.height // target_scale) * target_scale\n",
    "image = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "image = image.resize((image.width // target_scale, image.height // target_scale), resample=pil_image.BICUBIC)\n",
    "image = image.resize((image.width * target_scale, image.height * target_scale), resample=pil_image.BICUBIC)\n",
    "image.save(path_to_outputs + '_bicubic_x{}.png'.format(target_scale))\n",
    "\n",
    "image = np.array(image).astype(np.float32)\n",
    "ycbcr = convert_rgb_to_ycbcr(image)\n",
    "\n",
    "y = ycbcr[..., 0]\n",
    "y /= 255.\n",
    "y = torch.from_numpy(y).to(device)\n",
    "y = y.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    preds = model(y).clamp(0.0, 1.0)\n",
    "\n",
    "psnr = calc_psnr(y, preds)\n",
    "print('PSNR: {:.2f}'.format(psnr))\n",
    "\n",
    "preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
    "\n",
    "output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n",
    "output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
    "output = pil_image.fromarray(output)\n",
    "output.save(path_to_outputs + '_srcnn_x{}.png'.format(target_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--weights-file', type=str, required=True)\n",
    "    parser.add_argument('--image-file', type=str, required=True)\n",
    "    parser.add_argument('--scale', type=int, default=3)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = SRCNN().to(device)\n",
    "\n",
    "    state_dict = model.state_dict()\n",
    "    for n, p in torch.load(args.weights_file, map_location=lambda storage, loc: storage).items():\n",
    "        if n in state_dict.keys():\n",
    "            state_dict[n].copy_(p)\n",
    "        else:\n",
    "            raise KeyError(n)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    image = pil_image.open(args.image_file).convert('RGB')\n",
    "\n",
    "    image_width = (image.width // args.scale) * args.scale\n",
    "    image_height = (image.height // args.scale) * args.scale\n",
    "    image = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "    image = image.resize((image.width // args.scale, image.height // args.scale), resample=pil_image.BICUBIC)\n",
    "    image = image.resize((image.width * args.scale, image.height * args.scale), resample=pil_image.BICUBIC)\n",
    "    image.save(args.image_file.replace('.', '_bicubic_x{}.'.format(args.scale)))\n",
    "\n",
    "    image = np.array(image).astype(np.float32)\n",
    "    ycbcr = convert_rgb_to_ycbcr(image)\n",
    "\n",
    "    y = ycbcr[..., 0]\n",
    "    y /= 255.\n",
    "    y = torch.from_numpy(y).to(device)\n",
    "    y = y.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(y).clamp(0.0, 1.0)\n",
    "\n",
    "    psnr = calc_psnr(y, preds)\n",
    "    print('PSNR: {:.2f}'.format(psnr))\n",
    "\n",
    "    preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
    "\n",
    "    output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n",
    "    output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
    "    output = pil_image.fromarray(output)\n",
    "    output.save(args.image_file.replace('.', '_srcnn_x{}.'.format(args.scale)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
