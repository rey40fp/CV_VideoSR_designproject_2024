{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import SRCNN\n",
    "from datasets import TrainDataset, EvalDataset, TrainFeatDataset, EvalFeatDataset\n",
    "from utils import AverageMeter, calc_psnr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import  torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_16 = torchvision.models.vgg16(weights='DEFAULT').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(img, model_cut):\n",
    "    im = torch.stack((img,img,img), dim=2)[0].to(device)\n",
    "    return model_cut(im)\n",
    "\n",
    "def featureLoss(model,j):\n",
    "    def feature_loss(output, target):\n",
    "        \n",
    "        model_cut=nn.Sequential(*list(model.modules())[0][0:j])\n",
    "\n",
    "        output_ft = features(output, model_cut)\n",
    "        target_ft = features(target,model_cut)\n",
    "\n",
    "        scale = 1 / (np.prod(output_ft.shape))\n",
    "        \n",
    "        return (scale * torch.norm(output_ft - target_ft))\n",
    "    return feature_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/9: 100%|██████████| 21760/21760 [01:26<00:00, 252.56it/s, loss=0.011536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 17.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/9: 100%|██████████| 21760/21760 [01:24<00:00, 258.24it/s, loss=0.010442]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 19.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2/9: 100%|██████████| 21760/21760 [01:23<00:00, 261.29it/s, loss=0.010245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 21.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3/9: 100%|██████████| 21760/21760 [01:21<00:00, 265.74it/s, loss=0.010063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 21.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4/9: 100%|██████████| 21760/21760 [01:23<00:00, 259.23it/s, loss=0.009978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 21.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5/9: 100%|██████████| 21760/21760 [01:23<00:00, 259.63it/s, loss=0.009749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 20.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6/9: 100%|██████████| 21760/21760 [01:30<00:00, 239.88it/s, loss=0.009900]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 20.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7/9: 100%|██████████| 21760/21760 [01:27<00:00, 250.01it/s, loss=0.009618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 21.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8/9: 100%|██████████| 21760/21760 [01:25<00:00, 253.09it/s, loss=0.009566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 19.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9/9: 100%|██████████| 21760/21760 [01:25<00:00, 255.58it/s, loss=0.009503]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 19.40\n",
      "best epoch: 3, psnr: 21.69\n"
     ]
    }
   ],
   "source": [
    "num_workers = 8\n",
    "# all the arguments in variables with their default values\n",
    "train_file = 'original_training_data/x4/91-image_x4.h5' #TODO\n",
    "#train_file = 'original_training_data/for_training/AMVTG_004.h5' #TODO\n",
    "eval_file = 'original_training_data/x4/Set5_x4.h5' #TODO\n",
    "outputs_dir = 'outputs'\n",
    "scale = 4\n",
    "lr = 1e-4\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "num_workers = 8\n",
    "seed = 123\n",
    "\n",
    "# new output dir using the statics variables\n",
    "outputs_dir = os.path.join(outputs_dir, 'x{}'.format(scale))\n",
    "\n",
    "# if not os.path.exists(args.outputs_dir):\n",
    "#     os.makedirs(args.outputs_dir)\n",
    "\n",
    "\n",
    "if not os.path.exists(outputs_dir):\n",
    "    os.makedirs(outputs_dir)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model_orig = SRCNN().to(device)\n",
    "model_orig.load_state_dict(torch.load(\"pretrained/srcnn_x4.pth\", map_location=device))\n",
    "model_orig.to(device)\n",
    "model_orig.eval()\n",
    "\n",
    "model_feat = SRCNN().to(device)\n",
    "\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = featureLoss(list(vgg_16.children())[0],23) #This is the 3-3 ReLu block in the paper.\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model_feat.conv1.parameters()},\n",
    "    {'params': model_feat.conv2.parameters()},\n",
    "    {'params': model_feat.conv3.parameters(), 'lr': lr * 0.1}\n",
    "], lr=lr)\n",
    "\n",
    "train_dataset = TrainDataset(train_file)\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=True)\n",
    "eval_dataset = EvalDataset(eval_file)\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
    "\n",
    "best_weights = copy.deepcopy(model_feat.state_dict())\n",
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_feat.train()\n",
    "    epoch_losses = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size)) as t:\n",
    "        t.set_description('epoch: {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model_feat(inputs)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            epoch_losses.update(loss.item(), len(inputs))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
    "            t.update(len(inputs))\n",
    "\n",
    "    torch.save(model_feat.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n",
    "\n",
    "    model_feat.eval()\n",
    "    epoch_psnr = AverageMeter()\n",
    "\n",
    "    for data in eval_dataloader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model_feat(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "        epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
    "\n",
    "    print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
    "\n",
    "    if epoch_psnr.avg > best_psnr:\n",
    "        best_epoch = epoch\n",
    "        best_psnr = epoch_psnr.avg\n",
    "        best_weights = copy.deepcopy(model_feat.state_dict())\n",
    "\n",
    "print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
    "torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/9:   0%|          | 0/21760 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/9: 100%|██████████| 21760/21760 [00:56<00:00, 384.92it/s, loss=0.006608] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 28.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/9: 100%|██████████| 21760/21760 [00:55<00:00, 393.10it/s, loss=0.002877] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 28.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2/9: 100%|██████████| 21760/21760 [00:56<00:00, 386.72it/s, loss=0.002808] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3/9: 100%|██████████| 21760/21760 [00:55<00:00, 389.30it/s, loss=0.002772] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4/9: 100%|██████████| 21760/21760 [00:56<00:00, 381.98it/s, loss=0.002748] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5/9: 100%|██████████| 21760/21760 [00:59<00:00, 364.40it/s, loss=0.002730] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6/9: 100%|██████████| 21760/21760 [00:56<00:00, 385.00it/s, loss=0.002714] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7/9: 100%|██████████| 21760/21760 [00:57<00:00, 379.56it/s, loss=0.002698] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8/9: 100%|██████████| 21760/21760 [01:02<00:00, 350.11it/s, loss=0.002688] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9/9: 100%|██████████| 21760/21760 [00:56<00:00, 383.44it/s, loss=0.002675] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.36\n",
      "best epoch: 9, psnr: 29.36\n"
     ]
    }
   ],
   "source": [
    "model_MSE = SRCNN().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = featureLoss(model_orig, 2) #this number is j\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model_MSE.conv1.parameters()},\n",
    "    {'params': model_MSE.conv2.parameters()},\n",
    "    {'params': model_MSE.conv3.parameters(), 'lr': lr * 0.1}\n",
    "], lr=lr)\n",
    "\n",
    "train_dataset = TrainDataset(train_file)\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=True)\n",
    "eval_dataset = EvalDataset(eval_file)\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
    "\n",
    "best_weights = copy.deepcopy(model_MSE.state_dict())\n",
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_MSE.train()\n",
    "    epoch_losses = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size)) as t:\n",
    "        t.set_description('epoch: {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model_MSE(inputs)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            epoch_losses.update(loss.item(), len(inputs))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
    "            t.update(len(inputs))\n",
    "\n",
    "    torch.save(model_MSE.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n",
    "\n",
    "    model_MSE.eval()\n",
    "    epoch_psnr = AverageMeter()\n",
    "\n",
    "    for data in eval_dataloader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model_MSE(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "        epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
    "\n",
    "    print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
    "\n",
    "    if epoch_psnr.avg > best_psnr:\n",
    "        best_epoch = epoch\n",
    "        best_psnr = epoch_psnr.avg\n",
    "        best_weights = copy.deepcopy(model_MSE.state_dict())\n",
    "\n",
    "print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
    "torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20.4760, device='mps:0') tensor(33.0503, device='mps:0')\n",
      "tensor(19.0577, device='mps:0') tensor(30.3439, device='mps:0')\n",
      "tensor(18.1012, device='mps:0') tensor(24.4742, device='mps:0')\n",
      "tensor(19.7343, device='mps:0') tensor(30.9082, device='mps:0')\n",
      "tensor(19.6061, device='mps:0') tensor(28.0476, device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor_str.py:137: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:283.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "for data in eval_dataloader:\n",
    "    inputs, labels = data\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds_feat = model_feat(inputs).clamp(0.0, 1.0)\n",
    "        preds_MSE = model_MSE(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "    print(calc_psnr(preds_feat, labels), calc_psnr(preds_MSE, labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
