{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import SRCNN\n",
    "from datasets import TrainDataset, EvalDataset\n",
    "from utils import AverageMeter, calc_psnr\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(img, model):\n",
    "    submodules=list(model.children())[0:-1]\n",
    "    features=[]\n",
    "    last = img.to(device)\n",
    "    for submodule in submodules:\n",
    "        last = submodule(last).to(device)\n",
    "        features.append(last)\n",
    "    return features\n",
    "\n",
    "def featureLoss(model,j):\n",
    "    def feature_loss(output, target):\n",
    "        output_ft = features(output, model)\n",
    "        target_ft = features(target,model)\n",
    "        feature_loss=[]\n",
    "\n",
    "        submodules=list(model.children())[0:-1]\n",
    "\n",
    "        for i in range(len(submodules)):\n",
    "            scale = 1 / (np.prod(output_ft[i].shape)* np.prod(submodules[i].kernel_size))\n",
    "            feature_loss.append(scale * torch.norm(output_ft[i] - target_ft[i]))\n",
    "        return feature_loss[j]\n",
    "    return feature_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/9:   0%|          | 0/21760 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/9: 100%|██████████| 21760/21760 [01:12<00:00, 301.90it/s, loss=0.000184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 28.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/9: 100%|██████████| 21760/21760 [01:11<00:00, 304.58it/s, loss=0.000168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 28.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2/9: 100%|██████████| 21760/21760 [01:10<00:00, 307.93it/s, loss=0.000167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 28.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3/9: 100%|██████████| 21760/21760 [01:09<00:00, 311.43it/s, loss=0.000166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 28.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4/9: 100%|██████████| 21760/21760 [01:09<00:00, 312.99it/s, loss=0.000165]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5/9: 100%|██████████| 21760/21760 [01:09<00:00, 312.18it/s, loss=0.000164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 28.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6/9: 100%|██████████| 21760/21760 [01:10<00:00, 310.66it/s, loss=0.000163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7/9: 100%|██████████| 21760/21760 [01:10<00:00, 307.92it/s, loss=0.000163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8/9: 100%|██████████| 21760/21760 [01:10<00:00, 310.41it/s, loss=0.000163]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9/9: 100%|██████████| 21760/21760 [16:22<00:00, 22.14it/s, loss=0.000162] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.10\n",
      "best epoch: 8, psnr: 29.12\n"
     ]
    }
   ],
   "source": [
    "num_workers = 8\n",
    "# all the arguments in variables with their default values\n",
    "train_file = 'original_training_data/x4/91-image_x4.h5' #TODO\n",
    "#train_file = 'original_training_data/for_training/AMVTG_004.h5' #TODO\n",
    "eval_file = 'original_training_data/x4/Set5_x4.h5' #TODO\n",
    "outputs_dir = 'outputs'\n",
    "scale = 4\n",
    "lr = 1e-4\n",
    "batch_size = 16\n",
    "num_epochs = 10\n",
    "num_workers = 8\n",
    "seed = 123\n",
    "\n",
    "# new output dir using the statics variables\n",
    "outputs_dir = os.path.join(outputs_dir, 'x{}'.format(scale))\n",
    "\n",
    "# if not os.path.exists(args.outputs_dir):\n",
    "#     os.makedirs(args.outputs_dir)\n",
    "\n",
    "\n",
    "if not os.path.exists(outputs_dir):\n",
    "    os.makedirs(outputs_dir)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model_orig = SRCNN().to(device)\n",
    "model_orig.load_state_dict(torch.load(\"pretrained/srcnn_x4.pth\", map_location=device))\n",
    "model_orig.to(device)\n",
    "model_orig.eval()\n",
    "\n",
    "model_feat = SRCNN().to(device)\n",
    "\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = featureLoss(model_orig, 2) #this number is j\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model_feat.conv1.parameters()},\n",
    "    {'params': model_feat.conv2.parameters()},\n",
    "    {'params': model_feat.conv3.parameters(), 'lr': lr * 0.1}\n",
    "], lr=lr)\n",
    "\n",
    "train_dataset = TrainDataset(train_file)\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=True)\n",
    "eval_dataset = EvalDataset(eval_file)\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
    "\n",
    "best_weights = copy.deepcopy(model_feat.state_dict())\n",
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_feat.train()\n",
    "    epoch_losses = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size)) as t:\n",
    "        t.set_description('epoch: {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model_feat(inputs)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            epoch_losses.update(loss.item(), len(inputs))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
    "            t.update(len(inputs))\n",
    "\n",
    "    torch.save(model_feat.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n",
    "\n",
    "    model_feat.eval()\n",
    "    epoch_psnr = AverageMeter()\n",
    "\n",
    "    for data in eval_dataloader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model_feat(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "        epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
    "\n",
    "    print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
    "\n",
    "    if epoch_psnr.avg > best_psnr:\n",
    "        best_epoch = epoch\n",
    "        best_psnr = epoch_psnr.avg\n",
    "        best_weights = copy.deepcopy(model_feat.state_dict())\n",
    "\n",
    "print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
    "torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/9: 100%|██████████| 21760/21760 [16:19<00:00, 22.21it/s, loss=0.006608]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 28.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/9: 100%|██████████| 21760/21760 [00:59<00:00, 364.12it/s, loss=0.002877] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 28.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2/9: 100%|██████████| 21760/21760 [00:55<00:00, 393.80it/s, loss=0.002808] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3/9: 100%|██████████| 21760/21760 [00:54<00:00, 401.73it/s, loss=0.002772] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4/9: 100%|██████████| 21760/21760 [00:57<00:00, 379.09it/s, loss=0.002748] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5/9: 100%|██████████| 21760/21760 [00:55<00:00, 394.46it/s, loss=0.002730] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6/9: 100%|██████████| 21760/21760 [00:55<00:00, 395.12it/s, loss=0.002714] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7/9: 100%|██████████| 21760/21760 [00:56<00:00, 386.06it/s, loss=0.002698] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8/9: 100%|██████████| 21760/21760 [00:57<00:00, 380.77it/s, loss=0.002688] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9/9: 100%|██████████| 21760/21760 [00:58<00:00, 372.77it/s, loss=0.002675] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 29.36\n",
      "best epoch: 9, psnr: 29.36\n"
     ]
    }
   ],
   "source": [
    "model_MSE = SRCNN().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = featureLoss(model_orig, 2) #this number is j\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model_MSE.conv1.parameters()},\n",
    "    {'params': model_MSE.conv2.parameters()},\n",
    "    {'params': model_MSE.conv3.parameters(), 'lr': lr * 0.1}\n",
    "], lr=lr)\n",
    "\n",
    "train_dataset = TrainDataset(train_file)\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=True)\n",
    "eval_dataset = EvalDataset(eval_file)\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
    "\n",
    "best_weights = copy.deepcopy(model_MSE.state_dict())\n",
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_MSE.train()\n",
    "    epoch_losses = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size)) as t:\n",
    "        t.set_description('epoch: {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model_MSE(inputs)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            epoch_losses.update(loss.item(), len(inputs))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
    "            t.update(len(inputs))\n",
    "\n",
    "    torch.save(model_MSE.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n",
    "\n",
    "    model_MSE.eval()\n",
    "    epoch_psnr = AverageMeter()\n",
    "\n",
    "    for data in eval_dataloader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model_MSE(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "        epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
    "\n",
    "    print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
    "\n",
    "    if epoch_psnr.avg > best_psnr:\n",
    "        best_epoch = epoch\n",
    "        best_psnr = epoch_psnr.avg\n",
    "        best_weights = copy.deepcopy(model_MSE.state_dict())\n",
    "\n",
    "print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
    "torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32.7767, device='mps:0') tensor(33.0503, device='mps:0')\n",
      "tensor(30.0175, device='mps:0') tensor(30.3439, device='mps:0')\n",
      "tensor(24.2898, device='mps:0') tensor(24.4742, device='mps:0')\n",
      "tensor(30.5397, device='mps:0') tensor(30.9082, device='mps:0')\n",
      "tensor(27.8911, device='mps:0') tensor(28.0476, device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor_str.py:137: UserWarning: MPS: nonzero op is supported natively starting from macOS 13.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:283.)\n",
      "  nonzero_finite_vals = torch.masked_select(\n"
     ]
    }
   ],
   "source": [
    "for data in eval_dataloader:\n",
    "    inputs, labels = data\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds_feat = model_feat(inputs).clamp(0.0, 1.0)\n",
    "        preds_MSE = model_MSE(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "    print(calc_psnr(preds_feat, labels), calc_psnr(preds_MSE, labels))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
