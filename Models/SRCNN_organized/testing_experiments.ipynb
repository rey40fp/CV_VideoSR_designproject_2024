{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import numpy as np\n",
    "import PIL.Image as pil_image\n",
    "import os\n",
    "\n",
    "from models import SRCNN, SRCNN_video\n",
    "from utils import convert_rgb_to_ycbcr, convert_ycbcr_to_rgb, calc_psnr\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame idx: 0 ---  SRCNN PSNR: 24.526451110839844\n",
      "Frame idx: 1 ---  SRCNN PSNR: 24.506916046142578\n",
      "Frame idx: 2 ---  SRCNN PSNR: 24.509681701660156\n",
      "Frame idx: 3 ---  SRCNN PSNR: 24.52451515197754\n",
      "Frame idx: 4 ---  SRCNN PSNR: 24.44962501525879\n",
      "Frame idx: 5 ---  SRCNN PSNR: 24.475175857543945\n",
      "Frame idx: 6 ---  SRCNN PSNR: 24.528913497924805\n",
      "Frame idx: 7 ---  SRCNN PSNR: 24.521081924438477\n",
      "Frame idx: 8 ---  SRCNN PSNR: 24.525861740112305\n",
      "Frame idx: 9 ---  SRCNN PSNR: 24.456911087036133\n",
      "Frame idx: 10 ---  SRCNN PSNR: 24.495269775390625\n",
      "Frame idx: 11 ---  SRCNN PSNR: 24.521902084350586\n",
      "Frame idx: 12 ---  SRCNN PSNR: 24.46906280517578\n",
      "Frame idx: 13 ---  SRCNN PSNR: 24.52183723449707\n",
      "Frame idx: 14 ---  SRCNN PSNR: 24.475507736206055\n",
      "Frame idx: 15 ---  SRCNN PSNR: 24.530380249023438\n",
      "Frame idx: 16 ---  SRCNN PSNR: 24.455615997314453\n",
      "Frame idx: 17 ---  SRCNN PSNR: 24.52719497680664\n",
      "Frame idx: 18 ---  SRCNN PSNR: 24.468820571899414\n",
      "Frame idx: 19 ---  SRCNN PSNR: 24.538400650024414\n",
      "Frame idx: 20 ---  SRCNN PSNR: 24.521442413330078\n",
      "Frame idx: 21 ---  SRCNN PSNR: 24.53030014038086\n",
      "Frame idx: 22 ---  SRCNN PSNR: 24.53211212158203\n",
      "Frame idx: 23 ---  SRCNN PSNR: 24.522428512573242\n",
      "Frame idx: 24 ---  SRCNN PSNR: 24.54914093017578\n",
      "Frame idx: 25 ---  SRCNN PSNR: 24.521100997924805\n",
      "Frame idx: 26 ---  SRCNN PSNR: 24.531118392944336\n",
      "Frame idx: 27 ---  SRCNN PSNR: 24.475311279296875\n",
      "Frame idx: 28 ---  SRCNN PSNR: 24.461956024169922\n",
      "Frame idx: 29 ---  SRCNN PSNR: 24.530838012695312\n",
      "Frame idx: 30 ---  SRCNN PSNR: 24.47187614440918\n",
      "Average SRCNN PSNR: 24.505699157714844\n",
      "Average Bicubic PSNR: 23.60063934326172\n",
      "Full List SRCNN:  [24.526451110839844, 24.506916046142578, 24.509681701660156, 24.52451515197754, 24.44962501525879, 24.475175857543945, 24.528913497924805, 24.521081924438477, 24.525861740112305, 24.456911087036133, 24.495269775390625, 24.521902084350586, 24.46906280517578, 24.52183723449707, 24.475507736206055, 24.530380249023438, 24.455615997314453, 24.52719497680664, 24.468820571899414, 24.538400650024414, 24.521442413330078, 24.53030014038086, 24.53211212158203, 24.522428512573242, 24.54914093017578, 24.521100997924805, 24.531118392944336, 24.475311279296875, 24.461956024169922, 24.530838012695312, 24.47187614440918]\n",
      "Full List Bicubic:  [23.616851806640625, 23.601398468017578, 23.604164123535156, 23.614215850830078, 23.549072265625, 23.572113037109375, 23.620176315307617, 23.610454559326172, 23.618764877319336, 23.55878448486328, 23.593204498291016, 23.616165161132812, 23.567691802978516, 23.614559173583984, 23.57578468322754, 23.62343978881836, 23.556650161743164, 23.62081527709961, 23.569866180419922, 23.62735366821289, 23.616985321044922, 23.623916625976562, 23.625089645385742, 23.618450164794922, 23.634929656982422, 23.610851287841797, 23.624771118164062, 23.575504302978516, 23.55850601196289, 23.625165939331055, 23.574140548706055]\n",
      "Average SRCNN SSIM: 0.5944514584557317\n",
      "Average Bicubic SSIM: 0.530679053730594\n"
     ]
    }
   ],
   "source": [
    "#### Code for runing test on a full video (all frames) ### NOT FOR SRCNN VIDEOOO!! Just for original SRCNN\n",
    "def run_full_video_tests_SRCNN(model_,test_set_path,path_to_weights,path_to_outputs,target_scale=4):\n",
    "    \n",
    "    # Get all pictures in the folder\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps') # Switch to \"cpu\" if you don't have apple silicon\n",
    "\n",
    "    # test_set_path = './videos/test_set/AMVTG_004/truth/'\n",
    "    bicubic_avg_ssim = []\n",
    "    bicubic_avg_psnr = []\n",
    "\n",
    "\n",
    "    srcnn_avg_psnr = []\n",
    "    srcnn_avg_ssim = []\n",
    "    \n",
    "    for idx,image_name in enumerate(os.listdir(test_set_path)):\n",
    "\n",
    "        path_to_image = test_set_path + image_name\n",
    "        cudnn.benchmark = True\n",
    "        model = model_().to(device)\n",
    "\n",
    "\n",
    "        state_dict = model.state_dict()\n",
    "        for n, p in torch.load(path_to_weights, map_location=lambda storage, loc: storage).items():\n",
    "            if n in state_dict.keys():\n",
    "                state_dict[n].copy_(p)\n",
    "            else:\n",
    "                raise KeyError(n)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "\n",
    "        image_org = pil_image.open(path_to_image).convert('RGB')\n",
    "        # print(type(image_org))\n",
    "        #printing info about the current image being processed \n",
    "        # print(f'Processing image {idx+1} ): {image_name}')\n",
    "        # print(f'Image Width: {image_org.width} Image Height: {image_org.height}')\n",
    "        # Why are we resizing the image in this way?\n",
    "        image_org.save(path_to_outputs + '_original.png')\n",
    "        image_width = (image_org.width // target_scale) * target_scale\n",
    "        image_height = (image_org.height // target_scale) * target_scale\n",
    "        image_bic = image_org.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "        image_bic = image_bic.resize((image_bic.width // target_scale, image_bic.height // target_scale), resample=pil_image.BICUBIC)\n",
    "        image_bic = image_bic.resize((image_bic.width * target_scale, image_bic.height * target_scale), resample=pil_image.BICUBIC)\n",
    "        # print(f\"BICUBIC\")\n",
    "        # print(f\"After resizing Image Width: {image_bic.width} Image Height: {image_bic.height}\")\n",
    "        image_bic.save(path_to_outputs + '_bicubic_x{}.png'.format(target_scale))\n",
    "\n",
    "        # bicubic_psnr = calc_psnr\n",
    "\n",
    "        image_org_y = np.array(image_org).astype(np.float32)\n",
    "        image_bic_y = np.array(image_bic).astype(np.float32)\n",
    "        ycbcr_org = convert_rgb_to_ycbcr(image_org_y)\n",
    "        ycbcr_bic = convert_rgb_to_ycbcr(image_bic_y)\n",
    "\n",
    "\n",
    "        # y = ycbcr[..., 0]\n",
    "        # y /= 255.\n",
    "        # y = torch.from_numpy(y).to(device)\n",
    "        # y = y.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # For original image\n",
    "        y_org = ycbcr_org[..., 0]\n",
    "        y_org /= 255.\n",
    "        y_org = torch.from_numpy(y_org).to(device)\n",
    "        y_org = y_org.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # For bicubic image\n",
    "        y_bic = ycbcr_bic[..., 0]\n",
    "        y_bic /= 255.\n",
    "        y_bic = torch.from_numpy(y_bic).to(device)\n",
    "        y_bic = y_bic.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(y_bic).clamp(0.0, 1.0)\n",
    "\n",
    "\n",
    "        psnr_srcnn = calc_psnr(y_org, preds)\n",
    "        psnr_bicubic = calc_psnr(y_org, y_bic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        srcnn_avg_psnr.append(psnr_srcnn)\n",
    "        bicubic_avg_psnr.append(psnr_bicubic)\n",
    "\n",
    "            \n",
    "        # print('SRCNN PSNR: {:.2f}'.format(psnr_srcnn))\n",
    "        print(f\"Frame idx: {idx} ---  SRCNN PSNR: {psnr_srcnn}\")\n",
    "\n",
    "        preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
    "\n",
    "        output = np.array([preds, ycbcr_bic[..., 1],  ycbcr_bic[..., 2]]).transpose([1, 2, 0])\n",
    "        output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
    "\n",
    "        srcnn_avg_ssim.append(ssim(image_org_y, output))\n",
    "\n",
    "        output = pil_image.fromarray(output)\n",
    "        \n",
    "        output.save(path_to_outputs + '_srcnn_x{}.png'.format(target_scale))\n",
    "        # ssim_srcnn = ssim(image_org_y, output)\n",
    "        bicubic_avg_ssim.append(ssim(image_org_y,image_bic_y))\n",
    "\n",
    "    print(f\"Average SRCNN PSNR: {sum(srcnn_avg_psnr)/len(srcnn_avg_psnr)}\")\n",
    "    print(f\"Average Bicubic PSNR: {sum(bicubic_avg_psnr)/len(bicubic_avg_psnr)}\")\n",
    "    srcnn_just_item = [t.item() for t in srcnn_avg_psnr]\n",
    "    bicubic_just_item = [t.item() for t in bicubic_avg_psnr]\n",
    "    print(f\"Full List SRCNN:  {repr(srcnn_just_item)}\")\n",
    "    print(f\"Full List Bicubic:  {repr(bicubic_just_item)}\")\n",
    "    print(f\"Average SRCNN SSIM: {sum(srcnn_avg_ssim)/len(srcnn_avg_ssim)}\")\n",
    "    print(f\"Average Bicubic SSIM: {sum(bicubic_avg_ssim)/len(bicubic_avg_ssim)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path_to_weights= 'pretrained/srcnn_x4.pth'\n",
    "test_set_path = './videos/test_set/AMVTG_004/truth/'\n",
    "# test_set_path = './videos/test_set/veni3_011/truth/'\n",
    "# test_set_path = './videos/test_set/land9_007/truth/'\n",
    "path_to_outputs = 'outputs/test_video_output/AMVTG_004'\n",
    "run_full_video_tests_SRCNN(SRCNN,test_set_path,path_to_weights,path_to_outputs,target_scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPERS CODE!\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "# from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "# import cv2\n",
    "\n",
    "\n",
    "\n",
    "#Manual SSIM calculation\n",
    "def ssim(img1, img2):\n",
    "    \"\"\"SSIM values range between -1 and 1, where 1 indicates perfect similarity. Close to 1 is good (little perceptual difference)\n",
    "    SSIM = 0 suggest no correlation between the strucutral information i nthe two images (rare case). \n",
    "    SSIM < 0 suggest that the images are very different. They have structural changes (inverted colors or \n",
    "    other significant transformations).\"\"\"\n",
    "    C1 = (0.01 * 255)**2\n",
    "    C2 = (0.03 * 255)**2\n",
    "\n",
    "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "    window = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "    def compute_ssim(img1, img2):\n",
    "        mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # Valid region\n",
    "        mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "        mu1_sq = mu1**2\n",
    "        mu2_sq = mu2**2\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "        \n",
    "        sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "        sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "        sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "        \n",
    "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "        return ssim_map.mean()\n",
    "\n",
    "    # Convert the images to float64 and separate the channels\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    ssim_scores = []\n",
    "    for i in range(3):  # Assuming img1 and img2 are RGB images\n",
    "        ssim_scores.append(compute_ssim(img1[:,:,i], img2[:,:,i]))\n",
    "\n",
    "    return np.mean(ssim_scores)\n",
    "\n",
    "# Example usage\n",
    "# img1 = cv2.imread('path_to_hr_image.jpg', cv2.IMREAD_COLOR)\n",
    "# img2 = cv2.imread('path_to_sr_image.jpg', cv2.IMREAD_COLOR)\n",
    "# print(\"SSIM:\", ssim(img1, img2))\n",
    "\n",
    "\n",
    "# SSIM using skimage.metrics\n",
    "def compute_ssim(img1, img2):\n",
    "    # Assume img1 and img2 are already loaded and are in BGR format as loaded by OpenCV\n",
    "    # Convert images to grayscale\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Compute SSIM between two images\n",
    "    ssim_value, _ = compare_ssim(img1_gray, img2_gray, full=True)\n",
    "    return ssim_value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def bicubic_super_resolution(lr_image_path, target_dimensions):\n",
    "    # LR image\n",
    "    lr_image = cv2.imread(lr_image_path, cv2.IMREAD_COLOR)\n",
    "    # Basic bicubic interpolation\n",
    "    sr_image = cv2.resize(lr_image, target_dimensions, interpolation=cv2.INTER_CUBIC)\n",
    "    return sr_image\n",
    "\n",
    "\n",
    "# From Paper, PSNR calculation\n",
    "# def calc_psnr(img1, img2):\n",
    "#     return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n",
    "\n",
    "\n",
    "def calculate_psnr(hr_image, sr_image):\n",
    "    # Ensure the images are of the same dimension\n",
    "    if hr_image.shape != sr_image.shape:\n",
    "        raise ValueError(\"HR and SR images must have the same dimensions for PSNR calculation.\")\n",
    "\n",
    "    # Mean Squared Error (MSE) between the HR and SR images\n",
    "    mse = np.mean((hr_image - sr_image) ** 2)\n",
    "    \n",
    "    if mse == 0:\n",
    "        return float('inf')  # Infinite PSNR means no error\n",
    "    else:\n",
    "        # PSNR\n",
    "        max_pixel = 255.0\n",
    "        psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "        return psnr\n",
    "\n",
    "# # Example usage\n",
    "# # hr_image_path = 'path_to_high_res_image.jpg'\n",
    "# # lr_image_path = 'path_to_low_res_image.jpg'\n",
    "# lr_image_path = 'Datasets/Set14/Set14_LR_x4/comic.png'\n",
    "# hr_image_path = 'Datasets/Set14/Set14_HR/comic.png'\n",
    "# hr_image = cv2.imread(hr_image_path, cv2.IMREAD_COLOR)  # Read HR image to get dimensions\n",
    "\n",
    "# # Generate the super-resolved image using the dimensions of the HR image\n",
    "# lr_image = cv2.imread(lr_image_path, cv2.IMREAD_COLOR)\n",
    "# sr_image = bicubic_super_resolution(lr_image_path, (hr_image.shape[1], hr_image.shape[0]))\n",
    "\n",
    "# # Calculate PSNR\n",
    "# psnr_value = calculate_psnr(hr_image, sr_image)\n",
    "\n",
    "# im_to_plot = [lr_image, hr_image, sr_image]\n",
    "\n",
    "# #Printing LR, HR, and SR image shapes.\n",
    "# print(f'LR Image shape: {lr_image.shape}')\n",
    "# print(f'HR Image shape: {hr_image.shape}')\n",
    "# print(f'SR Image shape: {sr_image.shape}')\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(15, 5))\n",
    "\n",
    "# for count,im in enumerate(im_to_plot):\n",
    "#     # convert bgr to rgb \n",
    "    \n",
    "#     plt.subplot(1,3,count+1)\n",
    "#     if count ==0:\n",
    "#         plt.title('LR Image')   \n",
    "#     elif count ==1:\n",
    "#         plt.title('HR Image')\n",
    "#     else:\n",
    "#         plt.title('Super Resolution (Bicubic)')\n",
    "#     plt.axis('off')\n",
    "    \n",
    "#     rgb = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "#     plt.imshow(rgb, cmap = plt.cm.Spectral)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"PSNR value:\", psnr_value)\n",
    "\n",
    "# print(\"SSIM value:\", ssim(hr_image, sr_image))\n",
    "# print(\"SSIM value using skimage.metrics:\", compute_ssim(hr_image, sr_image))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average SRCNN PSNR: 32.32741928100586\n",
      "Average Bicubic PSNR: 31.428936004638672\n",
      "Full List SRCNN:  [32.276798248291016, 32.33149719238281, 32.325050354003906, 32.23936462402344, 32.22751998901367, 32.26617431640625, 32.28605651855469, 32.286651611328125, 32.30243682861328, 32.295501708984375, 32.29678726196289, 32.25708770751953, 32.212337493896484, 32.20344161987305, 32.236122131347656, 32.278255462646484, 32.2684440612793, 32.288063049316406, 32.33387756347656, 32.327430725097656, 32.38397216796875, 32.393775939941406, 32.37760925292969, 32.38277816772461, 32.38229751586914, 32.38859939575195, 32.390682220458984, 32.42462921142578, 32.4670524597168, 32.511756896972656, 32.50786590576172]\n",
      "Full List Bicubic:  [31.371917724609375, 31.398056030273438, 31.38946533203125, 31.325408935546875, 31.324148178100586, 31.34177017211914, 31.34881019592285, 31.34765625, 31.364585876464844, 31.36539077758789, 31.376361846923828, 31.35464096069336, 31.324462890625, 31.321537017822266, 31.35280418395996, 31.385467529296875, 31.387046813964844, 31.40871810913086, 31.444324493408203, 31.436471939086914, 31.468915939331055, 31.48261833190918, 31.48017692565918, 31.48937225341797, 31.501340866088867, 31.51563262939453, 31.526201248168945, 31.561195373535156, 31.600250244140625, 31.659547805786133, 31.642696380615234]\n",
      "Average SRCNN SSIM: 0.8802287437110756\n",
      "Average Bicubic SSIM: 0.8517346274685405\n"
     ]
    }
   ],
   "source": [
    "# Just for SSIM, Delete later\n",
    "# Code for SRCNN_video model \n",
    "def run_full_video_tests_SRCNN_video(model_,test_set_path,path_to_weights,path_to_outputs,target_scale=4):\n",
    "    \n",
    "    # Get all pictures in the folder\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps') # Switch to \"cpu\" if you don't have apple silicon\n",
    "\n",
    "    # test_set_path = './videos/test_set/AMVTG_004/truth/'\n",
    "\n",
    "\n",
    "    bicubic_avg_ssim = []\n",
    "    bicubic_avg_psnr = []\n",
    "\n",
    "\n",
    "    srcnn_avg_psnr = []\n",
    "    srcnn_avg_ssim = []\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    images = sorted(os.listdir(test_set_path))\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    model = model_().to(device)\n",
    "\n",
    "\n",
    "    state_dict = model.state_dict()\n",
    "    for n, p in torch.load(path_to_weights, map_location=lambda storage, loc: storage).items():\n",
    "        if n in state_dict.keys():\n",
    "            state_dict[n].copy_(p)\n",
    "        else:\n",
    "            raise KeyError(n)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for idx,image_name in enumerate(images):\n",
    "\n",
    "        path_to_image = test_set_path + image_name\n",
    "\n",
    "        # Load current and previous image (use the first image twice if it's the first frame)\n",
    "        current_image = pil_image.open(path_to_image).convert('RGB')\n",
    "        if idx > 0:\n",
    "            prev_image = pil_image.open(os.path.join(test_set_path, images[idx-1])).convert('RGB')\n",
    "        else:\n",
    "            prev_image = current_image\n",
    "        \n",
    "        current_image.save(path_to_outputs + '_original.png')\n",
    "        #########\n",
    "        # Resize images for SRCNN_video processing\n",
    "        width, height = current_image.size\n",
    "        width = (width // target_scale) * target_scale\n",
    "        height = (height // target_scale) * target_scale\n",
    "        current_image_bic = current_image.resize((width, height), resample=pil_image.BICUBIC)\n",
    "        current_image_bic = current_image_bic.resize((current_image_bic.width // target_scale, current_image_bic.height // target_scale), resample=pil_image.BICUBIC)\n",
    "        current_image_bic = current_image_bic.resize((current_image_bic.width * target_scale, current_image_bic.height * target_scale), resample=pil_image.BICUBIC)\n",
    "        current_image_bic.save(path_to_outputs + '_bicubic_x{}.png'.format(target_scale))\n",
    "\n",
    "        \n",
    "        prev_image_bic = prev_image.resize((width, height), resample=pil_image.BICUBIC)\n",
    "        prev_image_bic = prev_image_bic.resize((prev_image_bic.width // target_scale, prev_image_bic.height // target_scale), resample=pil_image.BICUBIC)\n",
    "        prev_image_bic = prev_image_bic.resize((prev_image_bic.width * target_scale, prev_image_bic.height * target_scale), resample=pil_image.BICUBIC)\n",
    "\n",
    "        \n",
    "        current_image_y = np.array(current_image).astype(np.float32)\n",
    "        current_image_bic_y = np.array(current_image_bic).astype(np.float32)\n",
    "\n",
    "        prev_image_y = np.array(prev_image).astype(np.float32)\n",
    "        prev_image_bic_y = np.array(prev_image_bic).astype(np.float32)\n",
    "\n",
    "        ycbcr_current = convert_rgb_to_ycbcr(current_image_y)\n",
    "        ycbcr_current_bic = convert_rgb_to_ycbcr(current_image_bic_y) # USE THIS\n",
    "        ycbcr_prev_bic = convert_rgb_to_ycbcr(prev_image_bic_y) ## USE THIS\n",
    "\n",
    "        y_org = ycbcr_current[..., 0]\n",
    "        y_org /= 255.\n",
    "        y_org = torch.from_numpy(y_org).to(device)\n",
    "        y_org = y_org.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        y_prev_bic = ycbcr_prev_bic[..., 0]\n",
    "        y_prev_bic /= 255.\n",
    "        y_prev_bic  = torch.from_numpy(y_prev_bic).to(device)\n",
    "        y_prev_bic = y_prev_bic.unsqueeze(0).unsqueeze(0)\n",
    "        # print(f\"y_prev_bic shape: {y_prev_bic.shape}\")\n",
    "\n",
    "        y_bic = ycbcr_current_bic[..., 0]\n",
    "        y_bic /= 255.\n",
    "        y_bic = torch.from_numpy(y_bic).to(device)\n",
    "        y_bic = y_bic.unsqueeze(0).unsqueeze(0)\n",
    "        # print(f\"y_bic shape: {y_bic.shape}\")\n",
    "        \n",
    "        # current_y = to_tensor(current_image.convert('YCbCr'))[0].unsqueeze(0).to(device)\n",
    "        # prev_y = to_tensor(prev_image.convert('YCbCr'))[0].unsqueeze(0).to(device)\n",
    "  \n",
    "\n",
    "        input_tensor = torch.cat([y_bic,y_prev_bic], dim=1).to(device)\n",
    "        # print(f\"input_tensor shape: {input_tensor.shape}\")\n",
    "        # input_tensor = torch.cat([current_y, prev_y], dim=0).unsqueeze(0).to(device)\n",
    "        \n",
    "        ################\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(input_tensor).clamp(0.0, 1.0)\n",
    "\n",
    "\n",
    "        psnr_srcnn = calc_psnr(y_org, preds)\n",
    "        psnr_bicubic = calc_psnr(y_org, y_bic)\n",
    "\n",
    "\n",
    "        srcnn_avg_psnr.append(psnr_srcnn)\n",
    "        bicubic_avg_psnr.append(psnr_bicubic)\n",
    "\n",
    "            \n",
    "        # print('SRCNN PSNR: {:.2f}'.format(psnr_srcnn))\n",
    "        #Print frame as well\n",
    "        \n",
    "        # print(f\"Frame idx: {idx} ---  SRCNN PSNR: {psnr_srcnn}\")\n",
    "\n",
    "        preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)\n",
    "\n",
    "        output = np.array([preds, ycbcr_current[..., 1],  ycbcr_current[..., 2]]).transpose([1, 2, 0])\n",
    "        output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(np.uint8)\n",
    "        srcnn_avg_ssim.append(ssim(current_image_y, output))\n",
    "        output = pil_image.fromarray(output)\n",
    "        output.save(path_to_outputs + '_srcnn_x{}.png'.format(target_scale))\n",
    "        bicubic_avg_ssim.append(ssim(current_image_y,current_image_bic_y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Average SRCNN PSNR: {sum(srcnn_avg_psnr)/len(srcnn_avg_psnr)}\")\n",
    "    print(f\"Average Bicubic PSNR: {sum(bicubic_avg_psnr)/len(bicubic_avg_psnr)}\")\n",
    "    srcnn_just_item = [t.item() for t in srcnn_avg_psnr]\n",
    "    bicubic_just_item = [t.item() for t in bicubic_avg_psnr]\n",
    "    print(f\"Full List SRCNN:  {repr(srcnn_just_item)}\")\n",
    "    print(f\"Full List Bicubic:  {repr(bicubic_just_item)}\")\n",
    "    print(f\"Average SRCNN SSIM: {sum(srcnn_avg_ssim)/len(srcnn_avg_ssim)}\")\n",
    "    print(f\"Average Bicubic SSIM: {sum(bicubic_avg_ssim)/len(bicubic_avg_ssim)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# path_to_weights= 'outputs/x4/best.pth'\n",
    "# path_to_weights= 'outputs/x4/previous_only_10_epochs_3databases/best.pth'\n",
    "path_to_weights= 'outputs/x4/SRCNN_video_v2_trained/best.pth'\n",
    "# test_set_path = './videos/test_set/AMVTG_004/truth/'\n",
    "# test_set_path = './videos/test_set/veni3_011/truth/'\n",
    "test_set_path = './videos/test_set/land9_007/truth/'\n",
    "path_to_outputs = 'outputs/test_video_srcnn_custom/AMVTG_004'\n",
    "run_full_video_tests_SRCNN_video(SRCNN_video,test_set_path,path_to_weights,path_to_outputs,target_scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
