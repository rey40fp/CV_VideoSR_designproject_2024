{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import SRCNN, SRCNN_video\n",
    "from datasets import TrainDataset, EvalDataset, TrainDataset_3D, EvalDataset_3D\n",
    "from utils import AverageMeter, calc_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0/9: 100%|██████████| 74240/74240 [01:13<00:00, 1011.38it/s, loss=0.012667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 23.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1/9: 100%|██████████| 74240/74240 [01:13<00:00, 1016.83it/s, loss=0.004150]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 24.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2/9: 100%|██████████| 74240/74240 [01:12<00:00, 1017.49it/s, loss=0.003670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 24.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 3/9: 100%|██████████| 74240/74240 [01:12<00:00, 1017.60it/s, loss=0.003461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 24.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 4/9: 100%|██████████| 74240/74240 [01:13<00:00, 1016.02it/s, loss=0.003328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 24.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 5/9: 100%|██████████| 74240/74240 [01:13<00:00, 1008.84it/s, loss=0.003226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 24.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 6/9: 100%|██████████| 74240/74240 [01:13<00:00, 1005.47it/s, loss=0.003138]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 24.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 7/9: 100%|██████████| 74240/74240 [01:13<00:00, 1006.97it/s, loss=0.003061]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 25.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 8/9: 100%|██████████| 74240/74240 [01:13<00:00, 1005.04it/s, loss=0.002993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 25.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 9/9: 100%|██████████| 74240/74240 [01:13<00:00, 1011.25it/s, loss=0.002931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval psnr: 25.15\n",
      "best epoch: 9, psnr: 25.15\n"
     ]
    }
   ],
   "source": [
    "# num_workers = 8\n",
    "# all the arguments in variables with their default values\n",
    "# train_file = 'original_training_data/x4/91-image_x4.h5' #TODO\n",
    "train_file = 'original_training_data/for_training/AMVTG_004.h5' #TODO\n",
    "# eval_file = 'original_training_data/x4/Set5_x4.h5' #TODO\n",
    "eval_file = 'preparing_data/prepare_out_3d/for_eval/AMVTG_004.h5' #TODO\n",
    "# eval_file = 'original_training_data/for_training/car05_001.h5' #TODO\n",
    "outputs_dir = 'outputs'\n",
    "scale = 4\n",
    "lr = 1e-4\n",
    "batch_size = 320\n",
    "num_epochs = 10\n",
    "num_workers = 12\n",
    "seed = 123\n",
    "\n",
    "# new output dir using the statics variables\n",
    "outputs_dir = os.path.join(outputs_dir, 'x{}'.format(scale))\n",
    "\n",
    "# if not os.path.exists(args.outputs_dir):\n",
    "#     os.makedirs(args.outputs_dir)\n",
    "\n",
    "\n",
    "if not os.path.exists(outputs_dir):\n",
    "    os.makedirs(outputs_dir)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'mps')\n",
    "\n",
    "# torch.manual_seed(args.seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "model = SRCNN_video().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.conv1.parameters()},\n",
    "    {'params': model.conv2.parameters()},\n",
    "    {'params': model.conv3.parameters(), 'lr': lr * 0.1}\n",
    "], lr=lr)\n",
    "\n",
    "train_dataset = TrainDataset_3D(train_file) # CHANGE HERE\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=True,\n",
    "                                drop_last=True)\n",
    "eval_dataset = EvalDataset_3D(eval_file)\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=1)\n",
    "\n",
    "best_weights = copy.deepcopy(model.state_dict())\n",
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_losses = AverageMeter()\n",
    "\n",
    "    with tqdm(total=(len(train_dataset) - len(train_dataset) % batch_size)) as t:\n",
    "        t.set_description('epoch: {}/{}'.format(epoch+1, num_epochs))\n",
    "\n",
    "        for data in train_dataloader:\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model(inputs)\n",
    "\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            epoch_losses.update(loss.item(), len(inputs))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
    "            t.update(len(inputs))\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(outputs_dir, 'epoch_{}.pth'.format(epoch)))\n",
    "\n",
    "    model.eval()\n",
    "    epoch_psnr = AverageMeter()\n",
    "\n",
    "    for data in eval_dataloader:\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "        epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
    "\n",
    "    print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
    "\n",
    "    if epoch_psnr.avg > best_psnr:\n",
    "        best_epoch = epoch\n",
    "        best_psnr = epoch_psnr.avg\n",
    "        best_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "print('best epoch: {}, psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
    "torch.save(best_weights, os.path.join(outputs_dir, 'best.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL DATA\n",
      "All keys: <KeysViewHDF5 ['hr', 'lr', 'prev_lr']> \n",
      "hr: Group\n",
      "All keys: <KeysViewHDF5 ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '4', '5', '6', '7', '8', '9']> \n",
      "    1: Dataset with shape (540, 960) and data type float32\n",
      "    10: Dataset with shape (540, 960) and data type float32\n",
      "    11: Dataset with shape (540, 960) and data type float32\n",
      "    12: Dataset with shape (540, 960) and data type float32\n",
      "    13: Dataset with shape (540, 960) and data type float32\n",
      "    14: Dataset with shape (540, 960) and data type float32\n",
      "    15: Dataset with shape (540, 960) and data type float32\n",
      "    16: Dataset with shape (540, 960) and data type float32\n",
      "    17: Dataset with shape (540, 960) and data type float32\n",
      "    18: Dataset with shape (540, 960) and data type float32\n",
      "    19: Dataset with shape (540, 960) and data type float32\n",
      "    2: Dataset with shape (540, 960) and data type float32\n",
      "    20: Dataset with shape (540, 960) and data type float32\n",
      "    21: Dataset with shape (540, 960) and data type float32\n",
      "    22: Dataset with shape (540, 960) and data type float32\n",
      "    23: Dataset with shape (540, 960) and data type float32\n",
      "    24: Dataset with shape (540, 960) and data type float32\n",
      "    25: Dataset with shape (540, 960) and data type float32\n",
      "    26: Dataset with shape (540, 960) and data type float32\n",
      "    27: Dataset with shape (540, 960) and data type float32\n",
      "    28: Dataset with shape (540, 960) and data type float32\n",
      "    29: Dataset with shape (540, 960) and data type float32\n",
      "    3: Dataset with shape (540, 960) and data type float32\n",
      "    30: Dataset with shape (540, 960) and data type float32\n",
      "    4: Dataset with shape (540, 960) and data type float32\n",
      "    5: Dataset with shape (540, 960) and data type float32\n",
      "    6: Dataset with shape (540, 960) and data type float32\n",
      "    7: Dataset with shape (540, 960) and data type float32\n",
      "    8: Dataset with shape (540, 960) and data type float32\n",
      "    9: Dataset with shape (540, 960) and data type float32\n",
      "lr: Group\n",
      "All keys: <KeysViewHDF5 ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '4', '5', '6', '7', '8', '9']> \n",
      "    1: Dataset with shape (540, 960) and data type float32\n",
      "    10: Dataset with shape (540, 960) and data type float32\n",
      "    11: Dataset with shape (540, 960) and data type float32\n",
      "    12: Dataset with shape (540, 960) and data type float32\n",
      "    13: Dataset with shape (540, 960) and data type float32\n",
      "    14: Dataset with shape (540, 960) and data type float32\n",
      "    15: Dataset with shape (540, 960) and data type float32\n",
      "    16: Dataset with shape (540, 960) and data type float32\n",
      "    17: Dataset with shape (540, 960) and data type float32\n",
      "    18: Dataset with shape (540, 960) and data type float32\n",
      "    19: Dataset with shape (540, 960) and data type float32\n",
      "    2: Dataset with shape (540, 960) and data type float32\n",
      "    20: Dataset with shape (540, 960) and data type float32\n",
      "    21: Dataset with shape (540, 960) and data type float32\n",
      "    22: Dataset with shape (540, 960) and data type float32\n",
      "    23: Dataset with shape (540, 960) and data type float32\n",
      "    24: Dataset with shape (540, 960) and data type float32\n",
      "    25: Dataset with shape (540, 960) and data type float32\n",
      "    26: Dataset with shape (540, 960) and data type float32\n",
      "    27: Dataset with shape (540, 960) and data type float32\n",
      "    28: Dataset with shape (540, 960) and data type float32\n",
      "    29: Dataset with shape (540, 960) and data type float32\n",
      "    3: Dataset with shape (540, 960) and data type float32\n",
      "    30: Dataset with shape (540, 960) and data type float32\n",
      "    4: Dataset with shape (540, 960) and data type float32\n",
      "    5: Dataset with shape (540, 960) and data type float32\n",
      "    6: Dataset with shape (540, 960) and data type float32\n",
      "    7: Dataset with shape (540, 960) and data type float32\n",
      "    8: Dataset with shape (540, 960) and data type float32\n",
      "    9: Dataset with shape (540, 960) and data type float32\n",
      "prev_lr: Group\n",
      "All keys: <KeysViewHDF5 ['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '4', '5', '6', '7', '8', '9']> \n",
      "    1: Dataset with shape (540, 960) and data type float32\n",
      "    10: Dataset with shape (540, 960) and data type float32\n",
      "    11: Dataset with shape (540, 960) and data type float32\n",
      "    12: Dataset with shape (540, 960) and data type float32\n",
      "    13: Dataset with shape (540, 960) and data type float32\n",
      "    14: Dataset with shape (540, 960) and data type float32\n",
      "    15: Dataset with shape (540, 960) and data type float32\n",
      "    16: Dataset with shape (540, 960) and data type float32\n",
      "    17: Dataset with shape (540, 960) and data type float32\n",
      "    18: Dataset with shape (540, 960) and data type float32\n",
      "    19: Dataset with shape (540, 960) and data type float32\n",
      "    2: Dataset with shape (540, 960) and data type float32\n",
      "    20: Dataset with shape (540, 960) and data type float32\n",
      "    21: Dataset with shape (540, 960) and data type float32\n",
      "    22: Dataset with shape (540, 960) and data type float32\n",
      "    23: Dataset with shape (540, 960) and data type float32\n",
      "    24: Dataset with shape (540, 960) and data type float32\n",
      "    25: Dataset with shape (540, 960) and data type float32\n",
      "    26: Dataset with shape (540, 960) and data type float32\n",
      "    27: Dataset with shape (540, 960) and data type float32\n",
      "    28: Dataset with shape (540, 960) and data type float32\n",
      "    29: Dataset with shape (540, 960) and data type float32\n",
      "    3: Dataset with shape (540, 960) and data type float32\n",
      "    30: Dataset with shape (540, 960) and data type float32\n",
      "    4: Dataset with shape (540, 960) and data type float32\n",
      "    5: Dataset with shape (540, 960) and data type float32\n",
      "    6: Dataset with shape (540, 960) and data type float32\n",
      "    7: Dataset with shape (540, 960) and data type float32\n",
      "    8: Dataset with shape (540, 960) and data type float32\n",
      "    9: Dataset with shape (540, 960) and data type float32\n",
      "TRAINING DATA\n",
      "All keys: <KeysViewHDF5 ['hr', 'lr', 'prev_lr']> \n",
      "hr: Dataset with shape (74370, 33, 33) and data type float32\n",
      "lr: Dataset with shape (74370, 33, 33) and data type float32\n",
      "prev_lr: Dataset with shape (74370, 33, 33) and data type float32\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def print_structure(h5_file, indent=''):\n",
    "    \"\"\"\n",
    "    Recursively prints the structure of an HDF5 file along with dataset shapes and data types.\n",
    "    \"\"\"\n",
    "    print(f\"All keys: {h5_file.keys()} \")\n",
    "    for key in h5_file.keys():   \n",
    "        item = h5_file[key]\n",
    "        print(f'{indent}{key}: ', end='')\n",
    "        if isinstance(item, h5py.Dataset):  # Check if the item is a dataset\n",
    "            print(f'Dataset with shape {item.shape} and data type {item.dtype}')\n",
    "        elif isinstance(item, h5py.Group):  # Check if the item is a group\n",
    "            print(f'Group')\n",
    "            print_structure(item, indent + '    ')  # Recurse into the group with increased indentation\n",
    "\n",
    "# Usage example\n",
    "            \n",
    "            #EVAL DATA\n",
    "# print('EVAL DATA')\n",
    "# with h5py.File('original_training_data/x4/Set5_x4.h5', 'r') as file:\n",
    "#     print_structure(file)\n",
    "#             # TRAINING DATA\n",
    "# print('TRAINING DATA')\n",
    "# with h5py.File('original_training_data/x4/91-image_x4.h5', 'r') as file:\n",
    "#     print_structure(file)\n",
    "\n",
    "\n",
    "\n",
    "print('EVAL DATA')\n",
    "with h5py.File('preparing_data/prepare_out_3d/for_eval/AMVTG_004.h5', 'r') as file:\n",
    "    print_structure(file)\n",
    "            # TRAINING DATA\n",
    "print('TRAINING DATA')\n",
    "with h5py.File('original_training_data/for_training/AMVTG_004.h5', 'r') as file:\n",
    "    print_structure(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_class",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
